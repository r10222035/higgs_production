{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from utils import phi_shift_and_flipping\n",
    "\n",
    "MAX_CONSTI = {\n",
    "    'Jet': 50,\n",
    "    'Tower': 250,\n",
    "    'Track': 150,\n",
    "    'Photon': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split SR (VBF) and BR (GGF) samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_keys(f):\n",
    "    keys = []\n",
    "    f.visit(lambda key : keys.append(key) if isinstance(f[key], h5py.Dataset) else None)\n",
    "    return keys\n",
    "\n",
    "def create_dataset(f, nevent, MAX_CONSTI):\n",
    "\n",
    "    f.create_dataset('J1/mask', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='|b1')\n",
    "    f.create_dataset('J1/pt', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='<f4')\n",
    "    f.create_dataset('J1/eta', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='<f4')\n",
    "    f.create_dataset('J1/phi', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('J2/mask', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='|b1')\n",
    "    f.create_dataset('J2/pt', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='<f4')\n",
    "    f.create_dataset('J2/eta', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='<f4')\n",
    "    f.create_dataset('J2/phi', (nevent, MAX_CONSTI['Jet']), maxshape=(None, MAX_CONSTI['Jet']), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('TOWER/mask', (nevent, MAX_CONSTI['Tower']), maxshape=(None, MAX_CONSTI['Tower']), dtype='|b1')\n",
    "    f.create_dataset('TOWER/pt', (nevent, MAX_CONSTI['Tower']), maxshape=(None, MAX_CONSTI['Tower']), dtype='<f4')\n",
    "    f.create_dataset('TOWER/eta', (nevent, MAX_CONSTI['Tower']), maxshape=(None, MAX_CONSTI['Tower']), dtype='<f4')\n",
    "    f.create_dataset('TOWER/phi', (nevent, MAX_CONSTI['Tower']), maxshape=(None, MAX_CONSTI['Tower']), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('TRACK/mask', (nevent, MAX_CONSTI['Track']), maxshape=(None, MAX_CONSTI['Track']), dtype='|b1')\n",
    "    f.create_dataset('TRACK/pt', (nevent, MAX_CONSTI['Track']), maxshape=(None, MAX_CONSTI['Track']), dtype='<f4')\n",
    "    f.create_dataset('TRACK/eta', (nevent, MAX_CONSTI['Track']), maxshape=(None, MAX_CONSTI['Track']), dtype='<f4')\n",
    "    f.create_dataset('TRACK/phi', (nevent, MAX_CONSTI['Track']), maxshape=(None, MAX_CONSTI['Track']), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('PHOTON/pt', (nevent, MAX_CONSTI['Photon']), maxshape=(None, MAX_CONSTI['Photon']), dtype='<f4')\n",
    "    f.create_dataset('PHOTON/eta', (nevent, MAX_CONSTI['Photon']), maxshape=(None, MAX_CONSTI['Photon']), dtype='<f4')\n",
    "    f.create_dataset('PHOTON/phi', (nevent, MAX_CONSTI['Photon']), maxshape=(None, MAX_CONSTI['Photon']), dtype='<f4')\n",
    "\n",
    "    f.create_dataset('EVENT/mjj', (nevent,), maxshape=(None,), dtype='<f4')\n",
    "    f.create_dataset('EVENT/deta', (nevent,), maxshape=(None,), dtype='<f4')\n",
    "    f.create_dataset('EVENT/type', (nevent,), maxshape=(None,), dtype='<i8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_SR_BR_mjj(h5_path, output_path, mjj_cut=300):\n",
    "\n",
    "    # read data\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        mjj = f['EVENT/mjj'][:]\n",
    "\n",
    "        SR_range = mjj > mjj_cut\n",
    "        BR_range = mjj < mjj_cut\n",
    "        \n",
    "        root, _ = os.path.splitext(output_path)\n",
    "        SR_path = f'{root}_in_SR.h5'\n",
    "        BR_path = f'{root}_in_BR.h5'\n",
    "\n",
    "        with h5py.File(SR_path, 'w') as f_SR, h5py.File(BR_path, 'w') as f_SB:\n",
    "\n",
    "            create_dataset(f_SR, SR_range.sum(), MAX_CONSTI)\n",
    "            create_dataset(f_SB, BR_range.sum(), MAX_CONSTI)\n",
    "\n",
    "            keys = get_dataset_keys(f_SR)\n",
    "\n",
    "            for key in keys:\n",
    "                f_SR[key][:] = f[key][:][SR_range]\n",
    "                f_SB[key][:] = f[key][:][BR_range]\n",
    "\n",
    "\n",
    "def split_SR_BR_deta(h5_path, output_path, deta_cut=3.1):\n",
    "\n",
    "    # read data\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        mjj = f['EVENT/mjj'][:]\n",
    "        deta = f['EVENT/deta'][:]\n",
    "\n",
    "        SR_range = deta > deta_cut\n",
    "        BR_range = deta < deta_cut\n",
    "        \n",
    "        root, _ = os.path.splitext(output_path)\n",
    "        SR_path = f'{root}_in_SR.h5'\n",
    "        BR_path = f'{root}_in_BR.h5'\n",
    "\n",
    "        with h5py.File(SR_path, 'w') as f_SR, h5py.File(BR_path, 'w') as f_SB:\n",
    "\n",
    "            create_dataset(f_SR, SR_range.sum(), MAX_CONSTI)\n",
    "            create_dataset(f_SB, BR_range.sum(), MAX_CONSTI)\n",
    "\n",
    "            keys = get_dataset_keys(f_SR)\n",
    "            for key in keys:\n",
    "                f_SR[key][:] = f[key][:][SR_range]\n",
    "                f_SB[key][:] = f[key][:][BR_range]\n",
    "\n",
    "\n",
    "def split_SR_BR_mjj_deta(h5_path, output_path, mjj_cut=300, deta_cut=3.1):\n",
    "\n",
    "    # read data\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        mjj = f['EVENT/mjj'][:]\n",
    "        deta = f['EVENT/deta'][:]\n",
    "\n",
    "        SR_range = (mjj > mjj_cut) & (deta > deta_cut)\n",
    "        BR_range = (mjj < mjj_cut) & (deta < deta_cut)\n",
    "        \n",
    "        root, _ = os.path.splitext(output_path)\n",
    "        SR_path = f'{root}_in_SR.h5'\n",
    "        BR_path = f'{root}_in_BR.h5'\n",
    "\n",
    "        with h5py.File(SR_path, 'w') as f_SR, h5py.File(BR_path, 'w') as f_SB:\n",
    "\n",
    "            create_dataset(f_SR, SR_range.sum(), MAX_CONSTI)\n",
    "            create_dataset(f_SB, BR_range.sum(), MAX_CONSTI)\n",
    "\n",
    "            keys = get_dataset_keys(f_SR)\n",
    "            for key in keys:\n",
    "                f_SR[key][:] = f[key][:][SR_range]\n",
    "                f_SB[key][:] = f[key][:][BR_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = 'data/GGF-03.h5'\n",
    "output_path = 'data/mjj_cut/GGF.h5'\n",
    "split_SR_BR_mjj(h5_path, output_path)\n",
    "\n",
    "h5_path = 'data/VBF-03.h5'\n",
    "output_path = 'data/mjj_cut/VBF.h5'\n",
    "split_SR_BR_mjj(h5_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\phi$ shifting and flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_event_image_h5(h5_path, out_h5):\n",
    "\n",
    "    shutil.copyfile(h5_path, out_h5)\n",
    "\n",
    "    with h5py.File(out_h5, 'a') as f_out:\n",
    "        print(out_h5)\n",
    "\n",
    "        event_pt = np.concatenate([f_out['TOWER/pt'][:], f_out['TRACK/pt'][:], f_out['PHOTON/pt'][:]], axis=1)\n",
    "        event_eta = np.concatenate([f_out['TOWER/eta'][:], f_out['TRACK/eta'][:], f_out['PHOTON/eta'][:]], axis=1)\n",
    "        event_phi = np.concatenate([f_out['TOWER/phi'][:], f_out['TRACK/phi'][:], f_out['PHOTON/phi'][:]], axis=1)\n",
    "\n",
    "        _, _, new_phi = phi_shift_and_flipping(event_pt, event_eta, event_phi)\n",
    "\n",
    "        f_out['TOWER/phi'][:] = new_phi[:, :MAX_CONSTI['Tower']]\n",
    "        f_out['TRACK/phi'][:] = new_phi[:, MAX_CONSTI['Tower']:MAX_CONSTI['Tower']+MAX_CONSTI['Track']]\n",
    "        f_out['PHOTON/phi'][:] = new_phi[:, MAX_CONSTI['Tower']+MAX_CONSTI['Track']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/mjj_cut/pre-processing/VBF_in_SR.h5\n",
      "./data/mjj_cut/pre-processing/VBF_in_BR.h5\n",
      "./data/mjj_cut/pre-processing/GGF_in_SR.h5\n",
      "./data/mjj_cut/pre-processing/GGF_in_BR.h5\n"
     ]
    }
   ],
   "source": [
    "for name in ['VBF_in_SR', 'VBF_in_BR', 'GGF_in_SR', 'GGF_in_BR']:\n",
    "    h5_path = f'./data/mjj_cut/{name}.h5'\n",
    "    out_h5 = f'./data/mjj_cut/pre-processing/{name}.h5'\n",
    "    to_event_image_h5(h5_path, out_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python pixelation.py ./data/mjj_cut/pre-processing/VBF_in_SR.h5 ./data/mjj_cut/pre-processing/40x40/VBF_in_SR.npy 40 &\n",
      "python pixelation.py ./data/mjj_cut/pre-processing/VBF_in_BR.h5 ./data/mjj_cut/pre-processing/40x40/VBF_in_BR.npy 40 &\n",
      "python pixelation.py ./data/mjj_cut/pre-processing/GGF_in_SR.h5 ./data/mjj_cut/pre-processing/40x40/GGF_in_SR.npy 40 &\n",
      "python pixelation.py ./data/mjj_cut/pre-processing/GGF_in_BR.h5 ./data/mjj_cut/pre-processing/40x40/GGF_in_BR.npy 40 &\n"
     ]
    }
   ],
   "source": [
    "res = 40\n",
    "h5_dir = './data/mjj_cut/pre-processing'\n",
    "npy_dir = f'./data/mjj_cut/pre-processing/{res}x{res}'\n",
    "\n",
    "# create output directory\n",
    "if not os.path.exists(npy_dir):\n",
    "    os.makedirs(npy_dir)\n",
    "\n",
    "for name in ['VBF_in_SR', 'VBF_in_BR', 'GGF_in_SR', 'GGF_in_BR']:\n",
    "    h5_path = os.path.join(h5_dir, f'{name}.h5')\n",
    "    npy_path = os.path.join(npy_dir, f'{name}.npy')\n",
    "    cmd = f'python pixelation.py {h5_path} {npy_path} {res} &'\n",
    "    print(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
